{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ventas: limpieza + persistencia (desde RAW)\n",
    "def clean_and_persist_ventas_from_raw(con: sqlite3.Connection) -> tuple[int, int, int]:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM raw_ventas\", con)\n",
    "    raw_rows = len(df)\n",
    "\n",
    "    if df.empty:\n",
    "        (QUALITY_DIR / \"ventas_invalidas.csv\").write_text(\"\", encoding=\"utf-8\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    df = strip_strings(df)\n",
    "    for c in [\"fecha\", \"id_cliente\", \"id_producto\", \"unidades\", \"precio_unitario\", \"_ingest_ts\", \"_source_file\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    df[\"fecha\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\").dt.date\n",
    "    df[\"unidades\"] = pd.to_numeric(df[\"unidades\"], errors=\"coerce\")\n",
    "    df[\"precio_unitario\"] = df[\"precio_unitario\"].apply(to_float_money)\n",
    "\n",
    "    valid = (\n",
    "        df[\"fecha\"].notna()\n",
    "        & df[\"unidades\"].notna() & (df[\"unidades\"] >= 0)\n",
    "        & df[\"precio_unitario\"].notna() & (df[\"precio_unitario\"] >= 0)\n",
    "        & df[\"id_cliente\"].notna() & (df[\"id_cliente\"] != \"\")\n",
    "        & df[\"id_producto\"].notna() & (df[\"id_producto\"] != \"\")\n",
    "    )\n",
    "    quarantine = df.loc[~valid].copy()\n",
    "    clean = df.loc[valid].copy()\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean = (\n",
    "            clean.sort_values(\"_ingest_ts\")\n",
    "                .drop_duplicates(subset=[\"fecha\", \"id_cliente\", \"id_producto\"], keep=\"last\")\n",
    "        )\n",
    "        clean[\"importe\"] = clean[\"unidades\"] * clean[\"precio_unitario\"]\n",
    "\n",
    "    quarantine.to_csv(QUALITY_DIR / \"ventas_invalidas.csv\", index=False)\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean.to_parquet(PARQUET_DIR / \"clean_ventas.parquet\", index=False)\n",
    "\n",
    "        upsert_sql = (ROOT / \"sql\" / \"10_upserts.sql\").read_text(encoding=\"utf-8\")\n",
    "        for _, r in clean.iterrows():\n",
    "            con.execute(\n",
    "                upsert_sql,\n",
    "                {\n",
    "                    \"fecha\": str(r[\"fecha\"]),\n",
    "                    \"idc\": r[\"id_cliente\"],\n",
    "                    \"idp\": r[\"id_producto\"],\n",
    "                    \"u\": float(r[\"unidades\"]),\n",
    "                    \"p\": float(r[\"precio_unitario\"]),\n",
    "                    \"ts\": r[\"_ingest_ts\"],\n",
    "                },\n",
    "            )\n",
    "        con.commit()\n",
    "\n",
    "    return raw_rows, len(clean), len(quarantine)\n",
    "\n",
    "# 2) Clientes: limpieza + persistencia (desde RAW)\n",
    "def clean_and_persist_clientes_from_raw(con: sqlite3.Connection) -> tuple[int, int, int]:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM raw_clientes\", con)\n",
    "    raw_rows = len(df)\n",
    "\n",
    "    if df.empty:\n",
    "        (QUALITY_DIR / \"clientes_invalidos.csv\").write_text(\"\", encoding=\"utf-8\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    df = strip_strings(df)\n",
    "    for c in [\"fecha\", \"nombre\", \"apellido\", \"id_cliente\", \"_ingest_ts\", \"_source_file\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    df[\"fecha\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\").dt.date\n",
    "    valid = df[\"id_cliente\"].notna() & (df[\"id_cliente\"] != \"\")\n",
    "    quarantine = df.loc[~valid].copy()\n",
    "    clean = df.loc[valid].copy()\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean = (\n",
    "            clean.sort_values(\"_ingest_ts\")\n",
    "                .drop_duplicates(subset=[\"id_cliente\"], keep=\"last\")\n",
    "        )\n",
    "\n",
    "    quarantine.to_csv(QUALITY_DIR / \"clientes_invalidos.csv\", index=False)\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean[[\"id_cliente\", \"nombre\", \"apellido\", \"fecha\"]].to_parquet(\n",
    "            PARQUET_DIR / \"dim_clientes.parquet\", index=False\n",
    "        )\n",
    "        clean[[\"id_cliente\", \"nombre\", \"apellido\", \"fecha\"]].to_sql(\n",
    "            \"dim_clientes\", con, if_exists=\"replace\", index=False\n",
    "        )\n",
    "\n",
    "    return raw_rows, len(clean), len(quarantine)\n",
    "\n",
    "# 3) Productos: limpieza + persistencia (desde RAW)\n",
    "def clean_and_persist_productos_from_raw(con: sqlite3.Connection) -> tuple[int, int, int]:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM raw_productos\", con)\n",
    "    raw_rows = len(df)\n",
    "\n",
    "    if df.empty:\n",
    "        (QUALITY_DIR / \"productos_invalidos.csv\").write_text(\"\", encoding=\"utf-8\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    df = strip_strings(df)\n",
    "    for c in [\"fecha_entrada\", \"nombre_producto\", \"id_producto\", \"unidades\", \"precio_unitario\", \"categoria\", \"_ingest_ts\", \"_source_file\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    df[\"fecha_entrada\"] = pd.to_datetime(df[\"fecha_entrada\"], errors=\"coerce\").dt.date\n",
    "    df[\"unidades\"] = pd.to_numeric(df[\"unidades\"], errors=\"coerce\")\n",
    "    df[\"precio_unitario\"] = df[\"precio_unitario\"].apply(to_float_money)\n",
    "\n",
    "    valid = (\n",
    "        df[\"id_producto\"].notna() & (df[\"id_producto\"] != \"\")\n",
    "        & df[\"precio_unitario\"].notna() & (df[\"precio_unitario\"] >= 0)\n",
    "        & df[\"unidades\"].notna() & (df[\"unidades\"] >= 0)\n",
    "    )\n",
    "    quarantine = df.loc[~valid].copy()\n",
    "    clean = df.loc[valid].copy()\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean = (\n",
    "            clean.sort_values(\"_ingest_ts\")\n",
    "            .drop_duplicates(subset=[\"id_producto\"], keep=\"last\")\n",
    "        )\n",
    "\n",
    "    quarantine.to_csv(QUALITY_DIR / \"productos_invalidos.csv\", index=False)\n",
    "\n",
    "    if not clean.empty:\n",
    "        clean[[\"id_producto\", \"nombre_producto\", \"categoria\", \"precio_unitario\", \"unidades\", \"fecha_entrada\"]].to_parquet(\n",
    "            PARQUET_DIR / \"dim_productos.parquet\", index=False\n",
    "        )\n",
    "        clean[[\"id_producto\", \"nombre_producto\", \"categoria\", \"precio_unitario\", \"unidades\", \"fecha_entrada\"]].to_sql(\n",
    "            \"dim_productos\", con, if_exists=\"replace\", index=False\n",
    "        )\n",
    "\n",
    "    return raw_rows, len(clean), len(quarantine)\n",
    "\n",
    "# Runner: llama a las tres limpiezas desde RAW\n",
    "if __name__ == \"__main__\":\n",
    "    DB = OUT / \"ut1.db\"\n",
    "    con = sqlite3.connect(DB)\n",
    "\n",
    "    # Asegura el esquema (clean_ventas, etc.) y vistas si aplica\n",
    "    # con.executescript((ROOT / \"sql\" / \"00_schema.sql\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    print(\"RAW counts:\",\n",
    "            con.execute(\"SELECT COUNT(*) FROM raw_ventas\").fetchone()[0],\n",
    "            con.execute(\"SELECT COUNT(*) FROM raw_clientes\").fetchone()[0],\n",
    "            con.execute(\"SELECT COUNT(*) FROM raw_productos\").fetchone()[0])\n",
    "\n",
    "    rv = clean_and_persist_ventas_from_raw(con)\n",
    "    rc = clean_and_persist_clientes_from_raw(con)\n",
    "    rp = clean_and_persist_productos_from_raw(con)\n",
    "    print(\"Ventas (raw, clean, quar):\", rv)\n",
    "    print(\"Clientes (raw, clean, quar):\", rc)\n",
    "    print(\"Productos (raw, clean, quar):\", rp)\n",
    "\n",
    "    con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
