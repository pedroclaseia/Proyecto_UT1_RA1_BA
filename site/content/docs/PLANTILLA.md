---
title: "Documento del Proyecto: Pipeline de Ingesti√≥n y Calidad de Datos"
tags: ["UT1","RA1","docs"]
version: "1.0.0"
owner: "equipo-alumno"
status: "draft"
---

# 1. Objetivo üéØ
El objetivo principal de este proyecto es implementar un **pipeline de datos (ETL)** que ingiera, limpie, valide y persista datos de ventas, clientes y productos. El prop√≥sito es transformar los datos de origen (capa **Bronce** - `raw`) en una capa de datos limpios y confiables (capa **Plata** - `clean`) para soportar an√°lisis de negocio (capa **Oro** - `views`).

---

# 2. Alcance üó∫Ô∏è
**Cubre:**
* La ingesta de archivos CSV para los dominios de Ventas, Clientes, y Productos.
* La aplicaci√≥n de reglas de calidad de datos (validaci√≥n de formatos, rangos, y nulos).
* La implementaci√≥n de un mecanismo de **idempotencia** y **deduplicaci√≥n** basado en clave primaria y marca de tiempo (`_ingest_ts`).
* La trazabilidad de los datos y el manejo de registros inv√°lidos en una capa de **Cuarentena** (`quarantine_X`).
* La generaci√≥n de un modelo anal√≠tico b√°sico (vistas) para m√©tricas clave (ej. `ventas_diarias`, `vw_producto_mas_vendido`).

**No Cubre:**
* La orquestaci√≥n autom√°tica del proceso (se ejecuta manualmente v√≠a `run.py`).
* La integraci√≥n con sistemas de origen o destino en la nube (se utiliza SQLite y Parquet local).
* El manejo de cambios en el esquema (schema evolution) de los archivos fuente.

---

# 3. Decisiones / Reglas ‚öôÔ∏è

## Estrategia de Ingesti√≥n
* **Modo:** **Batch** a demanda, procesando todos los archivos CSV disponibles en la fuente.
* **Idempotencia:** Implementada mediante sentencias **`UPSERT`** (`INSERT INTO ... ON CONFLICT DO UPDATE`).
* **Deduplicaci√≥n:** Se mantiene el registro con el **`_ingest_ts`** m√°s reciente sobre la clave primaria, aplicando la pol√≠tica de "√öltimo gana".

## Claves Naturales (PK en capa Plata - `clean`)
* **Ventas:** `(fecha, id_cliente, id_producto)`.
* **Clientes:** `(id_cliente)`.
* **Productos:** `(id_producto)`.

## Validaciones de Calidad (Cuarentena)
* **Malformaci√≥n:** Filas con un n√∫mero incorrecto de campos van a cuarentena con raz√≥n `parse_error_bad_field_count`.
* **Rangos:** `unidades` y `precio_unitario` deben ser num√©ricos y $\ge 0$.
* **Nulos/Formatos:** Campos obligatorios deben ser no nulos. Se valida el formato de fecha (ISO `YYYY-MM-DD`) y el formato del `id_cliente` (`^C\d{3}$`).
* **Estandarizaci√≥n:** Se aplica `TRIM` a todas las cadenas y `id_cliente` se normaliza a may√∫sculas.

---

# 4. Procedimiento / Pasos üõ†Ô∏è
Para reproducir la ejecuci√≥n completa del pipeline, siga los siguientes pasos:

1.  **Preparaci√≥n:** Aseg√∫rese de que los archivos de esquema (`00_schema.sql`), UPSERTs (`10_upserts.sql`), Vistas (`20_views.sql`), el script (`run.py`), y los datos CSV (`ventas.csv`, `clientes.csv`, `productos.csv`) se encuentran en sus directorios esperados.
2.  **Ejecuci√≥n:** Ejecutar el script principal desde la l√≠nea de comandos:
    ```bash
    python run.py
    ```
3.  **Resultado:** El script crear√° la base de datos **`ut1.db`** en la carpeta `/output` y los archivos Parquet/Cuarentena en `/output/parquet` y `/output/quality`.

---

# 5. Evidencias üìä
El script `run.py` proporciona los siguientes contadores de salida que sirven como evidencia de la ejecuci√≥n y el control de calidad:

| Dominio | Filas RAW | Filas CLEAN (Plata) | Filas QUARANTINE | PK: Clean |
| :--- | :--- | :--- | :--- | :--- |
| **Ventas** | 120 | 119 | 1 | `(fecha, id_cliente, id_producto)` |
| **Clientes** | 125 | 119 | 6 | `(id_cliente)` |
| **Productos** | 128 | 118 | 10 | `(id_producto)` |

> **Evidencia de Vistas (Capa Oro):** Las vistas `ventas_diarias`, `vw_producto_mas_vendido`, y `vw_producto_mas_caro` est√°n disponibles en `ut1.db` para su consulta.

---

# 6. Resultados (M√©tricas y Hallazgos) üìà

| M√©trica Clave (Per√≠odo Total) | Valor |
| :--- | :--- |
| **Ingresos Totales** | **‚Ç¨59,715** |
| **Transacciones Totales** | **119** |
| **Ticket Medio** | **‚Ç¨501.81** |

**Top Productos por Importe** (Igual contribuci√≥n en la muestra): **P005** (Televisor Sony 55"), **P025** (Herramienta 25), **P085** (Equipo 85) con ‚Ç¨3,500 cada uno.

**Hallazgos de Calidad:** Se ha detectado una tasa de cuarentena del **4.8% en Clientes** (por formato ID y fechas inv√°lidas) y **7.8% en Productos** (por valores num√©ricos negativos y fechas).

---

# 7. Lecciones Aprendidas üß†
* **Sali√≥ Bien:** La l√≥gica de **`UPSERT`** en `10_upserts.sql` y el uso del **`_ingest_ts`** demostraron ser robustos para garantizar la deduplicaci√≥n e idempotencia con la regla de "√∫ltimo gana". La separaci√≥n de errores en parseo vs. validaci√≥n es efectiva para el QA.
* **Mejorar/Distinto:** La validaci√≥n de n√∫meros (`to_float_money`, `pd.to_numeric`) fue necesaria, lo que indica un problema en el origen de los datos de `unidades` y `precio_unitario` (ej. valores con comas o mezclados en una sola columna como en `P015` de `productos.csv`). En el futuro, se podr√≠a a√±adir una validaci√≥n de que `fecha_entrada` no sea posterior a la fecha actual para la tabla de productos.

---

# 8. Pr√≥ximos Pasos ‚û°Ô∏è
* **Acci√≥n 1: Correcci√≥n de Origen.** Revisar los procesos que generan los CSVs para evitar fechas inv√°lidas (`2025-13-XX`, `2025-02-30`) y valores negativos/mal formateados, ya que causan la mayor parte de la cuarentena.
* **Acci√≥n 2: Finalizar Modelo Oro.** Crear la vista de **Top productos por Ingreso** (no solo por unidades) para tener un KPI completo.
* **Due√±o:** Equipo de Datos / QA.